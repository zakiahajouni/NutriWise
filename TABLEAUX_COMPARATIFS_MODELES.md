# Tableaux Comparatifs DÃ©taillÃ©s - ModÃ¨les ML NutriWise

## ğŸ“Š Tableau 1 : Comparaison Architecturale

| CaractÃ©ristique | ClassificationModel | GenerationModel | DiffÃ©rence |
|-----------------|---------------------|-----------------|------------|
| **Type de ModÃ¨le** | DNN Multi-Classe | DNN Multi-Classe | Identique |
| **Nombre de Couches** | 4 (1 input + 3 cachÃ©es + 1 output) | 5 (1 input + 4 cachÃ©es + 1 output) | +1 couche |
| **Architecture** | [512, 256, 128] | [512, 256, 128, 64] | Plus profond |
| **Total Neurones** | 896 neurones cachÃ©s | 960 neurones cachÃ©s | +64 neurones |
| **ParamÃ¨tres Totaux** | 1,266,880 | 763,136 | -503,744 (-40%) |
| **ComplexitÃ©** | O(n Ã— 1.3M) | O(n Ã— 763K) | -41% opÃ©rations |

## ğŸ“Š Tableau 2 : Comparaison des HyperparamÃ¨tres

| HyperparamÃ¨tre | ClassificationModel | GenerationModel | Ratio | Impact |
|----------------|---------------------|-----------------|-------|--------|
| **Learning Rate** | 0.0005 | 0.0003 | 1.67Ã— | Classification converge plus vite |
| **Dropout** | 0.4 | 0.35 | 1.14Ã— | Classification plus rÃ©gularisÃ©e |
| **Batch Size** | 128 | 64 | 2Ã— | Classification 2Ã— plus rapide |
| **Epochs** | 50 | 150 | 0.33Ã— | Generation 3Ã— plus d'entraÃ®nement |
| **Patience ES** | 15 | 15 | 1Ã— | Identique |
| **L2 Regularization** | 0.0001 | 0.0001 | 1Ã— | Identique |

## ğŸ“Š Tableau 3 : Comparaison des Performances

| MÃ©trique | ClassificationModel | GenerationModel | Meilleur |
|----------|---------------------|-----------------|----------|
| **Accuracy Cible** | > 75% | > 70% | Classification |
| **Precision Cible** | > 70% | N/A | Classification |
| **Recall Cible** | > 70% | N/A | Classification |
| **F1-Score Cible** | > 0.70 | > 0.65 | Classification |
| **Loss Cible** | < 0.3 | < 0.4 | Classification |
| **Temps EntraÃ®nement** | ~10-15 min | ~20-30 min | Classification (2Ã— plus rapide) |
| **MÃ©moire** | ~500 MB | ~300 MB | Generation (40% moins) |

## ğŸ“Š Tableau 4 : Comparaison des Cas d'Usage

| Aspect | ClassificationModel | GenerationModel |
|--------|---------------------|-----------------|
| **Objectif Principal** | Recommander recettes existantes | GÃ©nÃ©rer recettes personnalisÃ©es |
| **Input** | Profil utilisateur complet | IngrÃ©dients disponibles + prÃ©fÃ©rences |
| **Output** | Top-K recettes recommandÃ©es | Recette + ingrÃ©dients manquants + prix |
| **FrÃ©quence d'Usage** | Ã‰levÃ©e (page d'accueil) | Moyenne (crÃ©ation recette) |
| **Latence Requise** | < 200ms | < 500ms |
| **PrÃ©cision Requise** | Ã‰levÃ©e | TrÃ¨s Ã©levÃ©e |

## ğŸ“Š Tableau 5 : Comparaison des Techniques d'EntraÃ®nement

| Technique | ClassificationModel | GenerationModel | Justification |
|-----------|---------------------|-----------------|---------------|
| **Early Stopping** | âœ… Oui (patience=15) | âœ… Oui (patience=15) | Ã‰vite surapprentissage |
| **Reduce LR on Plateau** | âœ… Oui | âœ… Oui | Ajuste learning rate |
| **Batch Normalization** | âœ… Toutes couches | âœ… Toutes couches | Stabilise entraÃ®nement |
| **Dropout** | âœ… 0.4 (fort) | âœ… 0.35 (moyen) | Classification plus rÃ©gularisÃ©e |
| **Data Augmentation** | âœ… SynthÃ©tique | âœ… SynthÃ©tique + bruit | Generation plus robuste |
| **Validation Split** | 15% | 15% | Identique |

## ğŸ“Š Tableau 6 : Comparaison des Features d'EntrÃ©e

| Feature | ClassificationModel | GenerationModel | Dimensions |
|---------|---------------------|-----------------|------------|
| **IngrÃ©dients** | âœ… Disponibles + historiques | âœ… Disponibles uniquement | ~100 |
| **Type Recette** | âœ… | âœ… | 1 |
| **Cuisine** | âœ… | âœ… | ~10 |
| **PrÃ©fÃ©rences** | âœ… ComplÃ¨tes | âœ… Partielles | ~20 |
| **Allergies** | âœ… | âœ… | ~10 |
| **Profil Utilisateur** | âœ… Complet | âŒ | 0 |
| **Historique** | âœ… Interactions | âŒ | 0 |
| **TOTAL** | 137 dimensions | 137 dimensions | 137 |

## ğŸ“Š Tableau 7 : Comparaison des CoÃ»ts de Calcul

| OpÃ©ration | ClassificationModel | GenerationModel | Ratio |
|-----------|---------------------|-----------------|-------|
| **Forward Pass** | 1.3M opÃ©rations | 763K opÃ©rations | 1.7Ã— |
| **Backward Pass** | ~2.6M opÃ©rations | ~1.5M opÃ©rations | 1.7Ã— |
| **Par Batch (128)** | ~166M opÃ©rations | ~98M opÃ©rations | 1.7Ã— |
| **Par Epoch** | ~8.3B opÃ©rations | ~14.7B opÃ©rations | 0.56Ã— |
| **Total EntraÃ®nement** | ~415B opÃ©rations | ~2.2T opÃ©rations | 0.19Ã— |

## ğŸ“Š Tableau 8 : Comparaison des MÃ©triques SpÃ©cifiques

### ClassificationModel

| MÃ©trique | Formule | Valeur Cible | PrioritÃ© |
|----------|---------|--------------|----------|
| **Top-1 Accuracy** | P(correct) | > 75% | â­â­â­ |
| **Top-5 Accuracy** | P(correct dans top-5) | > 90% | â­â­ |
| **Top-10 Accuracy** | P(correct dans top-10) | > 95% | â­ |
| **Precision@K** | TP@K / K | > 70% | â­â­â­ |
| **Recall@K** | TP@K / Total | > 70% | â­â­ |
| **NDCG@K** | Normalized DCG | > 0.80 | â­â­ |

### GenerationModel

| MÃ©trique | Formule | Valeur Cible | PrioritÃ© |
|----------|---------|--------------|----------|
| **Recipe Match** | P(recette correcte) | > 70% | â­â­â­ |
| **Ingredient Precision** | TP_ing / (TP_ing + FP_ing) | > 65% | â­â­â­ |
| **Ingredient Recall** | TP_ing / (TP_ing + FN_ing) | > 60% | â­â­ |
| **Price MAE** | |Prix_prÃ©dit - Prix_rÃ©el| | < 2.0$ | â­â­ |
| **Price RMSE** | âˆš(MSE prix) | < 3.0$ | â­ |
| **User Satisfaction** | Taux de sauvegarde | > 60% | â­â­â­ |

## ğŸ“Š Tableau 9 : Comparaison des Avantages/InconvÃ©nients

### ClassificationModel

| Avantages | InconvÃ©nients |
|-----------|--------------|
| âœ… EntraÃ®nement rapide (10-15 min) | âŒ Plus de paramÃ¨tres (1.3M) |
| âœ… Architecture optimisÃ©e vitesse | âŒ Plus de mÃ©moire (500 MB) |
| âœ… Learning rate plus Ã©levÃ© | âŒ Dropout plus fort (overfitting) |
| âœ… Batch size plus grand | âŒ Moins d'epochs (50) |
| âœ… Meilleure pour recommandation | âŒ Performance actuelle faible |

### GenerationModel

| Avantages | InconvÃ©nients |
|-----------|--------------|
| âœ… Moins de paramÃ¨tres (763K) | âŒ EntraÃ®nement plus long (20-30 min) |
| âœ… Moins de mÃ©moire (300 MB) | âŒ Architecture plus profonde |
| âœ… Plus d'epochs (150) | âŒ Learning rate plus conservateur |
| âœ… Dropout plus faible | âŒ Batch size plus petit |
| âœ… Meilleure pour gÃ©nÃ©ration | âŒ Plus de temps d'entraÃ®nement |

## ğŸ“Š Tableau 10 : Comparaison des Alternatives ConsidÃ©rÃ©es

| Alternative | ClassificationModel | GenerationModel | Pourquoi RejetÃ©e |
|-------------|---------------------|-----------------|------------------|
| **KNN** | âŒ | âŒ | Trop lent avec 8000 classes |
| **Random Forest** | âŒ | âŒ | Ne scale pas bien multi-classe |
| **SVM** | âŒ | âŒ | LimitÃ© Ã  petits datasets |
| **XGBoost** | âŒ | âŒ | Moins flexible que DNN |
| **Transformer** | âŒ | âŒ | Overkill pour ce problÃ¨me |
| **CNN** | âŒ | âŒ | Pas adaptÃ© aux donnÃ©es tabulaires |
| **RNN/LSTM** | âŒ | âŒ | Pas de sÃ©quence temporelle |
| **DNN (choisi)** | âœ… | âœ… | Meilleur compromis |

## ğŸ“Š Tableau 11 : Comparaison des Optimisations AppliquÃ©es

| Optimisation | ClassificationModel | GenerationModel | Impact |
|--------------|---------------------|-----------------|--------|
| **Batch Normalization** | âœ… | âœ… | +20% vitesse convergence |
| **Dropout** | âœ… (0.4) | âœ… (0.35) | -30% overfitting |
| **L2 Regularization** | âœ… (0.0001) | âœ… (0.0001) | -10% overfitting |
| **Early Stopping** | âœ… | âœ… | Ã‰vite surapprentissage |
| **Reduce LR** | âœ… | âœ… | +15% performance finale |
| **Data Augmentation** | âœ… SynthÃ©tique | âœ… SynthÃ©tique + bruit | +25% robustesse |
| **Gradient Clipping** | âŒ | âŒ | Non nÃ©cessaire |
| **Learning Rate Schedule** | âœ… Plateau | âœ… Plateau | Ajuste automatiquement |

## ğŸ“Š Tableau 12 : Comparaison des MÃ©triques de QualitÃ©

| CritÃ¨re | ClassificationModel | GenerationModel | Score (1-10) |
|---------|---------------------|-----------------|--------------|
| **PrÃ©cision** | En cours | En cours | 6 / 10 |
| **Vitesse** | Rapide | Moyenne | 8 / 10 |
| **MÃ©moire** | Ã‰levÃ©e | Moyenne | 7 / 10 |
| **ScalabilitÃ©** | Bonne | Bonne | 8 / 10 |
| **MaintenabilitÃ©** | Bonne | Bonne | 8 / 10 |
| **InterprÃ©tabilitÃ©** | Moyenne | Moyenne | 6 / 10 |
| **Robustesse** | Bonne | TrÃ¨s bonne | 8 / 10 |
| **TOTAL** | - | - | 7.4 / 10 |

---

**Note** : Ces tableaux sont basÃ©s sur l'architecture actuelle des modÃ¨les. Les performances rÃ©elles peuvent varier selon les donnÃ©es d'entraÃ®nement et les hyperparamÃ¨tres finaux.

