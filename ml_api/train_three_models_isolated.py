#!/usr/bin/env python3
"""
Script isol√© pour entra√Æner les trois mod√®les de classification
Utilise un processus s√©par√© pour √©viter le blocage de l'IDE
"""

import sys
import os
import multiprocessing
import json

# D√âSACTIVER TOUS LES LOGS AVANT TOUT
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['KERAS_BACKEND'] = 'tensorflow'
os.environ['TF_NUM_INTEROP_THREADS'] = '1'
os.environ['TF_NUM_INTRAOP_THREADS'] = '1'

# Rediriger stdout vers un fichier pour √©viter le blocage
import io
import contextlib

def train_model_isolated(config_dict, model_num, output_file):
    """Fonction isol√©e pour entra√Æner un mod√®le dans un processus s√©par√©"""
    # R√©importer dans le processus enfant
    import warnings
    warnings.filterwarnings('ignore')
    
    # Configurer TensorFlow dans le processus enfant
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
    
    import tensorflow as tf
    tf.config.threading.set_inter_op_parallelism_threads(1)
    tf.config.threading.set_intra_op_parallelism_threads(1)
    tf.get_logger().setLevel('ERROR')
    
    from classification_model import ClassificationModel
    from database import save_model_to_db, activate_model
    
    try:
        # Rediriger la sortie vers le fichier
        with open(output_file, 'a') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"Mod√®le {model_num}: {config_dict['name']}\n")
            f.write(f"{'='*80}\n")
            f.write(f"Configuration:\n")
            f.write(f"  - Hidden Layers: {config_dict['hidden_layers']}\n")
            f.write(f"  - Learning Rate: {config_dict['learning_rate']}\n")
            f.write(f"  - Dropout: {config_dict['dropout']}\n")
            f.write(f"  - Epochs: {config_dict['epochs']}\n")
            f.write(f"  - Batch Size: {config_dict['batch_size']}\n")
            f.write(f"\nüéØ Entra√Ænement en cours...\n")
            f.flush()
        
        model = ClassificationModel()
        model_name = f"model_{model_num}"
        
        metrics = model.train(
            epochs=config_dict['epochs'],
            batch_size=config_dict['batch_size'],
            hidden_layers=config_dict['hidden_layers'],
            learning_rate=config_dict['learning_rate'],
            dropout=config_dict['dropout'],
            model_name=model_name
        )
        
        model_version = f"classification_model{model_num}_v{int(__import__('time').time())}"
        model_id = model.save(model_version)
        activate_model(model_id, 'recipe_classification')
        
        # √âcrire les r√©sultats dans le fichier
        with open(output_file, 'a') as f:
            f.write(f"\n‚úÖ Entra√Ænement termin√©!\n")
            f.write(f"üìä M√©triques:\n")
            f.write(f"  - Accuracy: {metrics['accuracy']*100:.2f}%\n")
            f.write(f"  - Precision: {metrics['precision']*100:.2f}%\n")
            f.write(f"  - Recall: {metrics['recall']*100:.2f}%\n")
            f.write(f"  - F1-Score: {metrics['f1Score']:.4f}\n")
            f.write(f"  - Loss: {metrics['loss']:.4f}\n")
            f.write(f"  - Model ID: {model_id}\n")
            f.flush()
        
        return {
            'success': True,
            'model_num': model_num,
            'name': config_dict['name'],
            'model_id': model_id,
            'metrics': metrics
        }
    except Exception as e:
        with open(output_file, 'a') as f:
            f.write(f"\n‚ùå Erreur: {str(e)}\n")
            f.flush()
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'model_num': model_num,
            'error': str(e)
        }

def main():
    """Fonction principale"""
    print("="*80)
    print("ENTRA√éNEMENT DES TROIS MOD√àLES DE CLASSIFICATION")
    print("="*80)
    print("\n‚ö†Ô∏è  Ce script utilise des processus s√©par√©s pour √©viter le blocage de l'IDE")
    print("üìù Les r√©sultats seront affich√©s en temps r√©el dans le terminal\n")
    
    # Configurations des mod√®les
    model_configs = [
        {
            'name': 'Mod√®le 1: Deep and Wide Network',
            'hidden_layers': [512, 512, 256, 128, 64],
            'learning_rate': 0.0005,
            'dropout': 0.4,
            'epochs': 200,
            'batch_size': 128
        },
        {
            'name': 'Mod√®le 2: Very Deep Network',
            'hidden_layers': [1024, 512, 256, 128, 64],
            'learning_rate': 0.0003,
            'dropout': 0.45,
            'epochs': 200,
            'batch_size': 128
        },
        {
            'name': 'Mod√®le 3: Balanced Deep Network',
            'hidden_layers': [768, 384, 192, 96, 48],
            'learning_rate': 0.0004,
            'dropout': 0.4,
            'epochs': 200,
            'batch_size': 128
        }
    ]
    
    # Cr√©er un fichier de sortie pour les logs
    log_file = 'training_logs.txt'
    with open(log_file, 'w') as f:
        f.write("Logs d'entra√Ænement des mod√®les\n")
        f.write("="*80 + "\n")
    
    print(f"üìù Les logs d√©taill√©s sont sauvegard√©s dans: {log_file}\n")
    
    results = []
    
    # Entra√Æner chaque mod√®le dans un processus s√©par√©
    for i, config in enumerate(model_configs, 1):
        print(f"üöÄ D√©marrage de l'entra√Ænement du Mod√®le {i}...")
        sys.stdout.flush()
        
        # Utiliser multiprocessing pour isoler compl√®tement
        process = multiprocessing.Process(
            target=train_model_isolated,
            args=(config, i, log_file)
        )
        process.start()
        process.join()  # Attendre la fin
        
        # Lire les r√©sultats depuis le fichier de log
        print(f"‚úÖ Mod√®le {i} termin√©. V√©rifiez {log_file} pour les d√©tails.\n")
        sys.stdout.flush()
    
    # Lire et afficher le r√©sum√© depuis le fichier de log
    print("\n" + "="*80)
    print("R√âSUM√â DES R√âSULTATS")
    print("="*80)
    
    try:
        with open(log_file, 'r') as f:
            print(f.read())
    except:
        print("Impossible de lire le fichier de log")
    
    print("\n‚úÖ Entra√Ænement termin√©! V√©rifiez le fichier training_logs.txt pour les d√©tails complets.")

if __name__ == '__main__':
    # Utiliser 'spawn' pour Windows/Linux pour isoler compl√®tement
    multiprocessing.set_start_method('spawn', force=True)
    main()



