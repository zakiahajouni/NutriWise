# Guide d'Entra√Ænement des Mod√®les de Classification

Ce guide explique comment entra√Æner les trois mod√®les de classification et voir leur accuracy.

## üìã Pr√©requis

1. **Environnement virtuel activ√©** :
   ```bash
   cd ml_api
   source venv/bin/activate
   ```

2. **D√©pendances install√©es** :
   ```bash
   pip install tensorflow scikit-learn numpy
   ```

## üöÄ M√©thode 1 : Script Bash (Recommand√©)

Ex√©cutez simplement le script bash :

```bash
cd ml_api
./train_models.sh
```

Ou avec bash explicitement :

```bash
cd ml_api
bash train_models.sh
```

## üêç M√©thode 2 : Script Python Direct

Si vous pr√©f√©rez ex√©cuter directement le script Python :

```bash
cd ml_api
source venv/bin/activate  # Si l'environnement virtuel n'est pas activ√©
python3 train_three_models.py
```

## üìä Les Trois Mod√®les

Le script entra√Æne automatiquement trois mod√®les avec des configurations diff√©rentes :

### Mod√®le 1: Deep and Wide Network
- **Architecture** : [512, 512, 256, 128, 64]
- **Learning Rate** : 0.0005
- **Dropout** : 0.4
- **Caract√©ristiques** : R√©seau large et profond, optimis√© pour une haute pr√©cision

### Mod√®le 2: Very Deep Network
- **Architecture** : [1024, 512, 256, 128, 64]
- **Learning Rate** : 0.0003
- **Dropout** : 0.45
- **Caract√©ristiques** : R√©seau tr√®s profond avec r√©gularisation importante

### Mod√®le 3: Balanced Deep Network
- **Architecture** : [768, 384, 192, 96, 48]
- **Learning Rate** : 0.0004
- **Dropout** : 0.4
- **Caract√©ristiques** : R√©seau √©quilibr√© entre profondeur et largeur

## üìà M√©triques Affich√©es

Pour chaque mod√®le, vous verrez :
- **Accuracy** : Pr√©cision globale du mod√®le (en %)
- **Precision** : Pr√©cision des pr√©dictions positives (en %)
- **Recall** : Rappel (couverture) (en %)
- **F1-Score** : Moyenne harmonique de Precision et Recall
- **Loss** : Perte du mod√®le (plus bas = mieux)

## üèÜ R√©sultat Final

√Ä la fin de l'entra√Ænement, vous verrez :
1. Un tableau comparatif des trois mod√®les class√©s par accuracy
2. Le meilleur mod√®le identifi√©
3. L'ID du mod√®le sauvegard√© en base de donn√©es

## ‚è±Ô∏è Temps d'Ex√©cution

L'entra√Ænement peut prendre plusieurs minutes selon :
- La taille du dataset
- La puissance de votre machine
- Le nombre d'epochs (200 par d√©faut)

**Estimation** : 10-30 minutes pour les trois mod√®les sur un dataset de 8000 recettes.

## üîß Personnalisation

Si vous voulez modifier les configurations, √©ditez le fichier `train_three_models.py` et modifiez les dictionnaires dans la fonction `main()` :

```python
model_configs = [
    {
        'name': 'Mod√®le 1: ...',
        'hidden_layers': [512, 512, 256, 128, 64],
        'learning_rate': 0.0005,
        'dropout': 0.4,
        'epochs': 200,  # Modifier ici
        'batch_size': 128  # Modifier ici
    },
    # ...
]
```

## ‚ùì D√©pannage

### Erreur : "ModuleNotFoundError: No module named 'tensorflow'"
**Solution** : Activez l'environnement virtuel et installez les d√©pendances :
```bash
source venv/bin/activate
pip install tensorflow scikit-learn numpy
```

### Erreur : "Dataset trop petit"
**Solution** : Assurez-vous d'avoir au moins 50 recettes dans votre dataset JSON.

### Erreur : "Out of memory"
**Solution** : R√©duisez le `batch_size` dans les configurations (par exemple, de 128 √† 64).

## üìù Notes

- Le meilleur mod√®le est automatiquement activ√© dans la base de donn√©es
- Chaque mod√®le est sauvegard√© avec un ID unique
- Les m√©triques sont affich√©es en temps r√©el pendant l'entra√Ænement
- Les mod√®les pr√©c√©dents restent dans la base de donn√©es mais ne sont pas activ√©s







