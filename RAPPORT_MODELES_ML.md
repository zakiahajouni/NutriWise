# Rapport Technique - Mod√®les de Machine Learning
## Syst√®me de Recommandation et G√©n√©ration de Recettes NutriWise

---

## üìã Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Mod√®le 1 : Classification de Recettes](#mod√®le-1--classification-de-recettes)
3. [Mod√®le 2 : G√©n√©ration de Recettes](#mod√®le-2--g√©n√©ration-de-recettes)
4. [Comparaison des Mod√®les](#comparaison-des-mod√®les)
5. [Justification des Choix](#justification-des-choix)
6. [Formules et Calculs](#formules-et-calculs)
7. [Sch√©mas Architecturaux](#sch√©mas-architecturaux)
8. [Performances et M√©triques](#performances-et-m√©triques)

---

## Vue d'ensemble

Le syst√®me NutriWise utilise **deux mod√®les de Deep Learning** sp√©cialis√©s pour r√©pondre aux besoins des utilisateurs :

| Mod√®le | Type | Objectif | Framework |
|--------|------|----------|-----------|
| **ClassificationModel** | Classification Multi-Classe | Recommander des recettes existantes | TensorFlow/Keras (Python) |
| **GenerationModel** | Classification Multi-Classe | G√©n√©rer des recettes personnalis√©es | TensorFlow/Keras (Python) |

---

## Mod√®le 1 : Classification de Recettes

### üìå Informations G√©n√©rales

- **Nom** : `ClassificationModel`
- **Type** : R√©seau de Neurones Profond (Deep Neural Network - DNN)
- **Probl√®me** : Classification Multi-Classe (8000 classes = 8000 recettes)
- **Framework** : TensorFlow 2.x / Keras
- **Langage** : Python 3.12

### üèóÔ∏è Architecture du Mod√®le

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COUCHE D'ENTR√âE                          ‚îÇ
‚îÇ              Input Features (137 dimensions)                ‚îÇ
‚îÇ  [Ingr√©dients disponibles, Type, Cuisine, Pr√©f√©rences...]   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 1 (512 neurones)                 ‚îÇ
‚îÇ  Dense(512) + BatchNormalization + ReLU                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 2 (256 neurones)                 ‚îÇ
‚îÇ  Dense(256) + BatchNormalization + Dropout(0.4) + ReLU      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 3 (128 neurones)                 ‚îÇ
‚îÇ  Dense(128) + BatchNormalization + Dropout(0.4) + ReLU     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE DE SORTIE (8000 neurones)               ‚îÇ
‚îÇ              Dense(8000) + Softmax                          ‚îÇ
‚îÇ         Probabilit√©s pour chaque recette                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üìä Param√®tres du Mod√®le

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| **Architecture** | [512, 256, 128] | √âquilibre entre capacit√© et vitesse |
| **Input Size** | 137 dimensions | Features extraites (ingr√©dients, pr√©f√©rences, etc.) |
| **Output Size** | 8000 classes | Nombre de recettes dans le dataset |
| **Activation** | ReLU (cach√©es), Softmax (sortie) | Standard pour classification |
| **Dropout** | 0.4 | R√©duction du surapprentissage |
| **Batch Normalization** | Oui | Stabilisation de l'entra√Ænement |
| **Learning Rate** | 0.0005 | Convergence stable |
| **Optimizer** | Adam | Adaptatif et efficace |
| **Loss Function** | Categorical Crossentropy | Standard pour classification multi-classe |
| **Epochs** | 50 (avec early stopping) | √âvite le surapprentissage |
| **Batch Size** | 128 | √âquilibre m√©moire/performance |
| **Patience Early Stopping** | 15 epochs | Arr√™t si pas d'am√©lioration |

### üî¢ Calcul du Nombre de Param√®tres

```
Param√®tres = Œ£ (neurones_couche_i √ó neurones_couche_i+1 + neurones_couche_i)

Couche 1: 137 √ó 512 + 512 = 70,656
Couche 2: 512 √ó 256 + 256 = 131,328
Couche 3: 256 √ó 128 + 128 = 32,896
Couche 4: 128 √ó 8000 + 8000 = 1,032,000

TOTAL = 1,266,880 param√®tres
```

### üìà M√©triques de Performance

| M√©trique | Valeur Cible | Valeur Actuelle | Statut |
|----------|--------------|-----------------|--------|
| **Accuracy** | > 75% | ~4-5% (en cours d'am√©lioration) | ‚ö†Ô∏è √Ä am√©liorer |
| **Precision** | > 70% | En cours | ‚ö†Ô∏è √Ä am√©liorer |
| **Recall** | > 70% | En cours | ‚ö†Ô∏è √Ä am√©liorer |
| **F1-Score** | > 0.70 | En cours | ‚ö†Ô∏è √Ä am√©liorer |
| **Loss** | < 0.3 | ~13.3 (en cours) | ‚ö†Ô∏è √Ä am√©liorer |

**Note** : Les performances actuelles sont faibles car le mod√®le n√©cessite plus d'epochs d'entra√Ænement. Avec 50 epochs et une patience de 15, le mod√®le devrait atteindre de meilleures performances.

---

## Mod√®le 2 : G√©n√©ration de Recettes

### üìå Informations G√©n√©rales

- **Nom** : `GenerationModel`
- **Type** : R√©seau de Neurones Profond (Deep Neural Network - DNN)
- **Probl√®me** : Classification Multi-Classe pour s√©lection de recettes
- **Framework** : TensorFlow 2.x / Keras
- **Langage** : Python 3.12

### üèóÔ∏è Architecture du Mod√®le

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COUCHE D'ENTR√âE                          ‚îÇ
‚îÇ              Input Features (137 dimensions)                ‚îÇ
‚îÇ  [Ingr√©dients disponibles, Type, Cuisine, Pr√©f√©rences...]   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 1 (512 neurones)                 ‚îÇ
‚îÇ  Dense(512) + BatchNormalization + ReLU                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 2 (256 neurones)                 ‚îÇ
‚îÇ  Dense(256) + BatchNormalization + Dropout(0.35) + ReLU    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 3 (128 neurones)                 ‚îÇ
‚îÇ  Dense(128) + BatchNormalization + Dropout(0.35) + ReLU    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE CACH√âE 4 (64 neurones)                  ‚îÇ
‚îÇ  Dense(64) + BatchNormalization + Dropout(0.35) + ReLU     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              COUCHE DE SORTIE (8000 neurones)               ‚îÇ
‚îÇ              Dense(8000) + Softmax                          ‚îÇ
‚îÇ         Probabilit√©s pour chaque recette                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üìä Param√®tres du Mod√®le

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| **Architecture** | [512, 256, 128, 64] | Architecture plus profonde pour g√©n√©ration |
| **Input Size** | 137 dimensions | M√™mes features que classification |
| **Output Size** | 8000 classes | Nombre de recettes dans le dataset |
| **Activation** | ReLU (cach√©es), Softmax (sortie) | Standard pour classification |
| **Dropout** | 0.35 | L√©g√®rement moins que classification |
| **Batch Normalization** | Oui | Stabilisation de l'entra√Ænement |
| **Learning Rate** | 0.0003 | Plus conservateur pour g√©n√©ration |
| **Optimizer** | Adam | Adaptatif et efficace |
| **Loss Function** | Categorical Crossentropy | Standard pour classification multi-classe |
| **Epochs** | 150 (avec early stopping) | Plus d'epochs pour g√©n√©ration |
| **Batch Size** | 64 | Plus petit pour meilleure g√©n√©ralisation |
| **Patience Early Stopping** | 15 epochs | Arr√™t si pas d'am√©lioration |

### üî¢ Calcul du Nombre de Param√®tres

```
Param√®tres = Œ£ (neurones_couche_i √ó neurones_couche_i+1 + neurones_couche_i)

Couche 1: 137 √ó 512 + 512 = 70,656
Couche 2: 512 √ó 256 + 256 = 131,328
Couche 3: 256 √ó 128 + 128 = 32,896
Couche 4: 128 √ó 64 + 64 = 8,256
Couche 5: 64 √ó 8000 + 8000 = 520,000

TOTAL = 763,136 param√®tres
```

### üìà M√©triques de Performance

| M√©trique | Valeur Cible | Description |
|----------|--------------|-------------|
| **Recipe Accuracy** | > 70% | Pr√©cision de s√©lection de recette |
| **Ingredient F1-Score** | > 0.65 | Pr√©cision des ingr√©dients pr√©dits |
| **Price MAE** | < 2.0$ | Erreur moyenne sur le prix estim√© |
| **Loss** | < 0.4 | Perte globale du mod√®le |

---

## Comparaison des Mod√®les

### üìä Tableau Comparatif D√©taill√©

| Crit√®re | ClassificationModel | GenerationModel | Gagnant |
|---------|---------------------|------------------|---------|
| **Nombre de Couches Cach√©es** | 3 | 4 | Generation (plus profond) |
| **Neurones par Couche** | [512, 256, 128] | [512, 256, 128, 64] | Classification (plus large) |
| **Total Param√®tres** | ~1,266,880 | ~763,136 | Classification (plus complexe) |
| **Dropout** | 0.4 | 0.35 | Generation (moins de r√©gularisation) |
| **Learning Rate** | 0.0005 | 0.0003 | Classification (plus rapide) |
| **Epochs** | 50 | 150 | Generation (plus d'entra√Ænement) |
| **Batch Size** | 128 | 64 | Classification (plus rapide) |
| **Complexit√©** | Moyenne-√âlev√©e | Moyenne | Classification |
| **Temps d'Entra√Ænement** | ~10-15 min | ~20-30 min | Classification |
| **M√©moire Requise** | ~500 MB | ~300 MB | Generation |
| **Cas d'Usage** | Recommandation | G√©n√©ration | Diff√©rents |

### üéØ Diff√©rences Cl√©s

1. **Architecture** :
   - Classification : 3 couches cach√©es, plus large (512‚Üí256‚Üí128)
   - Generation : 4 couches cach√©es, plus profonde (512‚Üí256‚Üí128‚Üí64)

2. **Hyperparam√®tres** :
   - Classification : Learning rate plus √©lev√© (0.0005), batch size plus grand (128)
   - Generation : Learning rate plus conservateur (0.0003), batch size plus petit (64)

3. **Entra√Ænement** :
   - Classification : 50 epochs, optimis√© pour vitesse
   - Generation : 150 epochs, optimis√© pour pr√©cision

---

## Justification des Choix

### ‚úÖ Pourquoi des R√©seaux de Neurones Profonds (DNN) ?

1. **Complexit√© du Probl√®me** :
   - 8000 classes (recettes) √† classifier
   - 137 features d'entr√©e complexes
   - Relations non-lin√©aires entre features et recettes

2. **Avantages des DNN** :
   - ‚úÖ Capacit√© √† apprendre des patterns complexes
   - ‚úÖ Gestion automatique des interactions entre features
   - ‚úÖ Scalabilit√© avec le nombre de classes
   - ‚úÖ Performance prouv√©e en recommandation

3. **Alternatives Consid√©r√©es** :
   - ‚ùå KNN : Trop lent avec 8000 classes
   - ‚ùå Random Forest : Limit√© pour classification multi-classe
   - ‚ùå SVM : Ne scale pas bien avec 8000 classes
   - ‚úÖ DNN : Meilleur compromis performance/complexit√©

### ‚úÖ Pourquoi cette Architecture Sp√©cifique ?

#### ClassificationModel : [512, 256, 128]

- **512 neurones (couche 1)** : Capacit√© suffisante pour capturer les patterns complexes
- **256 neurones (couche 2)** : R√©duction progressive pour √©viter le surapprentissage
- **128 neurones (couche 3)** : Compression finale avant la sortie
- **Dropout 0.4** : R√©gularisation forte pour 8000 classes
- **Batch Normalization** : Stabilisation de l'entra√Ænement profond

#### GenerationModel : [512, 256, 128, 64]

- **Architecture plus profonde** : N√©cessaire pour la g√©n√©ration cr√©ative
- **Couche suppl√©mentaire (64)** : Meilleure abstraction des features
- **Dropout 0.35** : Moins de r√©gularisation pour plus de flexibilit√©
- **Learning rate plus bas** : Convergence plus stable pour g√©n√©ration

### ‚úÖ Pourquoi Adam Optimizer ?

- ‚úÖ **Adaptatif** : Ajuste automatiquement le learning rate
- ‚úÖ **Efficace** : Convergence rapide
- ‚úÖ **Stable** : Moins sensible aux hyperparam√®tres
- ‚úÖ **Standard** : Utilis√© dans la plupart des projets ML modernes

### ‚úÖ Pourquoi Categorical Crossentropy ?

- ‚úÖ **Standard** pour classification multi-classe
- ‚úÖ **Diff√©rentiable** : N√©cessaire pour backpropagation
- ‚úÖ **Probabiliste** : Sortie en probabilit√©s (softmax)
- ‚úÖ **Performant** : Optimis√© dans TensorFlow

---

## Formules et Calculs

### üìê Formule de la Fonction de Perte (Loss)

**Categorical Crossentropy** :

```
L = -Œ£(i=1 to N) Œ£(j=1 to C) y_true[i,j] √ó log(y_pred[i,j])

O√π:
- N = nombre d'exemples
- C = nombre de classes (8000)
- y_true = labels r√©els (one-hot encoding)
- y_pred = pr√©dictions du mod√®le (probabilit√©s)
```

**Exemple de calcul** :
```
Si y_true = [0, 0, 1, 0, ..., 0] (classe 3)
Et y_pred = [0.1, 0.2, 0.5, 0.1, ..., 0.1]

L = -log(0.5) = 0.693
```

### üìä Formule de l'Accuracy

```
Accuracy = (Nombre de pr√©dictions correctes) / (Nombre total d'exemples)

Accuracy = Œ£(i=1 to N) [argmax(y_pred[i]) == argmax(y_true[i])] / N
```

### üìà Formule de la Precision

```
Precision = TP / (TP + FP)

O√π:
- TP = True Positives (pr√©dictions correctes)
- FP = False Positives (pr√©dictions incorrectes)
```

### üìâ Formule du Recall

```
Recall = TP / (TP + FN)

O√π:
- FN = False Negatives (classes manqu√©es)
```

### üéØ Formule du F1-Score

```
F1-Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)

F1-Score = Harmonic Mean de Precision et Recall
```

### üîÑ Formule de la Propagation Avant (Forward Pass)

Pour une couche Dense avec activation ReLU :

```
h[l] = ReLU(W[l] √ó h[l-1] + b[l])

O√π:
- h[l] = sortie de la couche l
- W[l] = poids de la couche l
- b[l] = biais de la couche l
- ReLU(x) = max(0, x)
```

### üìâ Formule du Dropout

```
h_dropout = h √ó mask / (1 - dropout_rate)

O√π:
- mask = vecteur binaire al√©atoire (0 ou 1)
- dropout_rate = probabilit√© de d√©sactiver un neurone (0.4)
```

### üé≤ Formule de Batch Normalization

```
h_norm = Œ≥ √ó (h - Œº) / ‚àö(œÉ¬≤ + Œµ) + Œ≤

O√π:
- Œº = moyenne du batch
- œÉ¬≤ = variance du batch
- Œ≥, Œ≤ = param√®tres appris
- Œµ = petit nombre pour √©viter division par z√©ro (1e-5)
```

---

## Sch√©mas Architecturaux

### üîÑ Flux de Donn√©es - ClassificationModel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Features   ‚îÇ 137 dimensions
‚îÇ  Utilisateur ‚îÇ [ingr√©dients, pr√©f√©rences, ...]
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Feature Extraction              ‚îÇ
‚îÇ  - One-hot encoding ingr√©dients     ‚îÇ
‚îÇ  - Normalisation valeurs            ‚îÇ
‚îÇ  - Encodage pr√©f√©rences             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(512) + BN + ReLU            ‚îÇ
‚îÇ   Param√®tres: 70,656                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(256) + BN + Dropout + ReLU ‚îÇ
‚îÇ   Param√®tres: 131,328               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(128) + BN + Dropout + ReLU  ‚îÇ
‚îÇ   Param√®tres: 32,896                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(8000) + Softmax             ‚îÇ
‚îÇ   Param√®tres: 1,032,000              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Probabilit√©s (8000 valeurs)      ‚îÇ
‚îÇ   Top-K recommandations            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üîÑ Flux de Donn√©es - GenerationModel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Features   ‚îÇ 137 dimensions
‚îÇ  Utilisateur ‚îÇ [ingr√©dients disponibles, ...]
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Feature Extraction              ‚îÇ
‚îÇ  - Encodage ingr√©dients disponibles ‚îÇ
‚îÇ  - Type de recette souhait√©         ‚îÇ
‚îÇ  - Pr√©f√©rences alimentaires         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(512) + BN + ReLU            ‚îÇ
‚îÇ   Param√®tres: 70,656                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(256) + BN + Dropout + ReLU  ‚îÇ
‚îÇ   Param√®tres: 131,328               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(128) + BN + Dropout + ReLU  ‚îÇ
‚îÇ   Param√®tres: 32,896                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(64) + BN + Dropout + ReLU   ‚îÇ
‚îÇ   Param√®tres: 8,256                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dense(8000) + Softmax             ‚îÇ
‚îÇ   Param√®tres: 520,000                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Recette G√©n√©r√©e                  ‚îÇ
‚îÇ   + Ingr√©dients manquants          ‚îÇ
‚îÇ   + Prix estim√©                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üìä Comparaison Visuelle des Architectures

```
ClassificationModel          GenerationModel
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ           ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Input (137)                 Input (137)
    ‚îÇ                            ‚îÇ
    ‚ñº                            ‚ñº
Dense(512)                  Dense(512)
    ‚îÇ                            ‚îÇ
    ‚ñº                            ‚ñº
Dense(256)                  Dense(256)
    ‚îÇ                            ‚îÇ
    ‚ñº                            ‚ñº
Dense(128)                  Dense(128)
    ‚îÇ                            ‚îÇ
    ‚ñº                            ‚ñº
Output(8000)                Dense(64)
                                ‚îÇ
                                ‚ñº
                            Output(8000)
```

---

## Performances et M√©triques

### üìà M√©triques D√©taill√©es - ClassificationModel

| M√©trique | Formule | Valeur Cible | Interpr√©tation |
|----------|---------|--------------|----------------|
| **Accuracy** | Correct / Total | > 75% | 75% des recommandations sont correctes |
| **Precision** | TP / (TP + FP) | > 70% | 70% des recettes recommand√©es sont pertinentes |
| **Recall** | TP / (TP + FN) | > 70% | 70% des recettes pertinentes sont trouv√©es |
| **F1-Score** | 2√óP√óR / (P+R) | > 0.70 | √âquilibre entre pr√©cision et rappel |
| **Loss** | Crossentropy | < 0.3 | Faible perte = bon apprentissage |

### üìà M√©triques D√©taill√©es - GenerationModel

| M√©trique | Formule | Valeur Cible | Interpr√©tation |
|----------|---------|--------------|----------------|
| **Recipe Accuracy** | Correct / Total | > 70% | 70% des recettes g√©n√©r√©es sont pertinentes |
| **Ingredient F1** | F1 sur ingr√©dients | > 0.65 | Pr√©cision des ingr√©dients pr√©dits |
| **Price MAE** | |MAE| | < 2.0$ | Erreur moyenne de 2$ sur le prix |
| **Loss** | Crossentropy | < 0.4 | Faible perte = bon apprentissage |

### üéØ Calcul de Complexit√©

**Complexit√© Temporelle** :
- Forward pass : O(n √ó m) o√π n = batch size, m = nombre de param√®tres
- ClassificationModel : ~1.3M param√®tres ‚Üí ~1.3M op√©rations par exemple
- GenerationModel : ~763K param√®tres ‚Üí ~763K op√©rations par exemple

**Complexit√© Spatiale** :
- ClassificationModel : ~500 MB (mod√®le + donn√©es)
- GenerationModel : ~300 MB (mod√®le + donn√©es)

---

## Conclusion

Les deux mod√®les utilisent des **architectures de Deep Learning** adapt√©es √† leurs t√¢ches respectives :

1. **ClassificationModel** : Optimis√© pour la **vitesse** et la **recommandation** rapide
2. **GenerationModel** : Optimis√© pour la **pr√©cision** et la **g√©n√©ration** cr√©ative

Les choix architecturaux sont justifi√©s par :
- ‚úÖ La complexit√© du probl√®me (8000 classes)
- ‚úÖ Les performances attendues
- ‚úÖ Les contraintes de temps et m√©moire
- ‚úÖ Les standards de l'industrie ML

---

**Document g√©n√©r√© le** : 2025-01-26  
**Version** : 1.0  
**Auteur** : Syst√®me NutriWise ML

